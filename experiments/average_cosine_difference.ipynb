{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import HateXplainRace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ksasse/miniconda3/envs/fairness/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shots = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate = HateXplainRace(\"../data/HateXplain/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, overall_demographics = hate.create_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 168/168 [00:04<00:00, 35.29it/s]\n",
      "Batches: 100%|██████████| 22/22 [00:00<00:00, 41.73it/s]\n"
     ]
    }
   ],
   "source": [
    "train_vectors = embedding.encode(train_df['prompts'].tolist(), batch_size = 32, show_progress_bar=True)\n",
    "test_vectors = embedding.encode(test_df['prompts'].tolist(), batch_size = 32, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.normalize_L2(train_vectors)\n",
    "\n",
    "faiss.normalize_L2(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_dim = train_vectors.shape[1]\n",
    "\n",
    "index = faiss.IndexFlatIP(vector_dim)\n",
    "\n",
    "index.add(train_vectors)\n",
    "\n",
    "distances, neighbors = index.search(test_vectors, shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Within\n",
    "pre_computed_inclusions = dict()\n",
    "\n",
    "for demographic in set(hate.demographics):\n",
    "    pre_computed_inclusions[demographic] = train_df[train_df.filtered_demographics == demographic]\n",
    "\n",
    "within_samples = []\n",
    "for row in test_df.itertuples():\n",
    "    filtered_df = pre_computed_inclusions[row.filtered_demographics]\n",
    "\n",
    "    within_sample = filtered_df[\"prompts\"].sample(n=shots).index.tolist()\n",
    "\n",
    "    within_samples.append(within_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Excluding\n",
    "pre_computed_exclusions = dict()\n",
    "\n",
    "for demographic in set(hate.demographics):\n",
    "    pre_computed_exclusions[demographic] = train_df[train_df.filtered_demographics != demographic]\n",
    "\n",
    "excluding_samples = []\n",
    "for row in test_df.itertuples():\n",
    "    filtered_df = pre_computed_exclusions[row.filtered_demographics]\n",
    "\n",
    "    excluding_sample = filtered_df[\"prompts\"].sample(n=shots).index.tolist()\n",
    "\n",
    "    excluding_samples.append(excluding_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans2 = KMeans(shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ksasse/miniconda3/envs/fairness/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans2.fit(train_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans2_distances, kmeans2_neighbors = index.search(kmeans2.cluster_centers_, 1)\n",
    "kmeans2_neighbors = [element for sublist in kmeans2_neighbors for element in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity_sample2 = train_df[\"prompts\"].iloc[kmeans2_neighbors].index.tolist()\n",
    "\n",
    "diversity_samples2 = [diversity_sample2 for x in range(len(test_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling a subset of 1280 / 5376 for training\n",
      "Clustering 1280 points in 768D to 5 clusters, redo 1 times, 1000 iterations\n",
      "  Preprocessing in 0.01 s\n",
      "  Iteration 999 (0.38 s, search 0.23 s): objective=294.327 imbalance=1.043 nsplit=0       \n"
     ]
    }
   ],
   "source": [
    "#Diversity\n",
    "kmeans = faiss.Kmeans(vector_dim, shots, verbose=True, niter=1000)\n",
    "kmeans.train(train_vectors)\n",
    "kmeans_distances, kmeans_neighbors = index.search(kmeans.centroids, 1)\n",
    "kmeans_neighbors = [element for sublist in kmeans_neighbors for element in sublist]\n",
    "\n",
    "diversity_sample = train_df[\"prompts\"].iloc[kmeans_neighbors].index.tolist()\n",
    "\n",
    "diversity_samples = [diversity_sample for x in range(len(test_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Post: america always was and always will be a white mans land all the jews and mud must leave or be forced out\\nQuestion: Does this post contain offensive language?\\nAnswer: yes',\n",
       " 'Post: this is what happens when niggers gain power there is not one street one neighborhood one city one state or one country that is better off once the nigger infects it\\nQuestion: Does this post contain offensive language?\\nAnswer: yes',\n",
       " 'Post: ffs people do unto others does not let foreigners and niggers come to your country and screw your daughters\\nQuestion: Does this post contain offensive language?\\nAnswer: yes',\n",
       " 'Post: yet another life saving development coming out of what muslim terrorists and arab land thieves claim is jewish occupied palestine\\nQuestion: Does this post contain offensive language?\\nAnswer: yes',\n",
       " 'Post: <user> <user> <user> nah boys nah im out niggers\\nQuestion: Does this post contain offensive language?\\nAnswer: yes']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"prompts\"].iloc[kmeans_neighbors].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random\n",
    "random_samples = []\n",
    "for row in test_df.itertuples():\n",
    "    random_sample = train_df[\"prompts\"].sample(n=shots).index.tolist()\n",
    "\n",
    "    random_samples.append(random_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,10) (5,5) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m average_cosine_differences_between_sim\u001b[39m.\u001b[39mappend(((sim_vectors \u001b[39m@\u001b[39m sim_vectors\u001b[39m.\u001b[39mT)\u001b[39m-\u001b[39m np\u001b[39m.\u001b[39midentity(shots))\u001b[39m.\u001b[39mmean())\n\u001b[1;32m     18\u001b[0m average_cosine_difference_between_random\u001b[39m.\u001b[39mappend(((random_vectors \u001b[39m@\u001b[39m random_vectors\u001b[39m.\u001b[39mT)\u001b[39m-\u001b[39m np\u001b[39m.\u001b[39midentity(shots))\u001b[39m.\u001b[39mmean())\n\u001b[0;32m---> 19\u001b[0m average_cosine_difference_between_diversity\u001b[39m.\u001b[39mappend(((diversity_vectors \u001b[39m@\u001b[39;49m diversity_vectors\u001b[39m.\u001b[39;49mT)\u001b[39m-\u001b[39;49m np\u001b[39m.\u001b[39;49midentity(shots))\u001b[39m.\u001b[39mmean())\n\u001b[1;32m     20\u001b[0m average_cosine_difference_between_excluding\u001b[39m.\u001b[39mappend(((excluding_vectors \u001b[39m@\u001b[39m excluding_vectors\u001b[39m.\u001b[39mT)\u001b[39m-\u001b[39m np\u001b[39m.\u001b[39midentity(shots))\u001b[39m.\u001b[39mmean())\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,10) (5,5) "
     ]
    }
   ],
   "source": [
    "average_cosine_differences_between_within = []\n",
    "average_cosine_differences_between_sim = []\n",
    "average_cosine_difference_between_random = []\n",
    "average_cosine_difference_between_diversity = []\n",
    "average_cosine_difference_between_excluding = []\n",
    "\n",
    "for i in range(len(within_samples)):\n",
    "\n",
    "    within_vectors = train_vectors[within_samples[i]]\n",
    "    sim_vectors = train_vectors[neighbors[i]]\n",
    "    random_vectors = train_vectors[random_samples[i]]\n",
    "    excluding_vectors = train_vectors[excluding_samples[i]]\n",
    "    diversity_vectors = train_vectors[diversity_samples2[i]]\n",
    "\n",
    "\n",
    "    average_cosine_differences_between_within.append(((within_vectors @ within_vectors.T)- np.identity(shots)).mean())\n",
    "    average_cosine_differences_between_sim.append(((sim_vectors @ sim_vectors.T)- np.identity(shots)).mean())\n",
    "    average_cosine_difference_between_random.append(((random_vectors @ random_vectors.T)- np.identity(shots)).mean())\n",
    "    average_cosine_difference_between_diversity.append(((diversity_vectors @ diversity_vectors.T)- np.identity(shots)).mean())\n",
    "    average_cosine_difference_between_excluding.append(((excluding_vectors @ excluding_vectors.T)- np.identity(shots)).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(average_cosine_differences_between_within).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(average_cosine_differences_between_sim).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(average_cosine_difference_between_random).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(average_cosine_difference_between_diversity).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(average_cosine_difference_between_excluding).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
